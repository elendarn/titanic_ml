{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2d9923c-9939-4d62-a85d-8c0132f03652",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from feature_extension_funcs import title_name, define_groups, prices, embarked_filled, cabin_filled, age_filled_tit, age_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88789921-ca32-4286-bbe9-3cce2a6ecbc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from ipynb.fs.full.titanic_EDA_feature_eng import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cc5639-ffef-41cc-9a3a-e094e0bd086b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# STEP1 : Get Data & Libraries\n",
    "##### Import libraries, load train data from Kaggle (already train/test splitted)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37c9c563-683b-40a1-b544-b33a6e6c0fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn                 import metrics\n",
    "from sklearn.dummy           import DummyClassifier\n",
    "from sklearn.linear_model    import LogisticRegression\n",
    "from sklearn.tree            import plot_tree, DecisionTreeClassifier\n",
    "from sklearn.ensemble        import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score, KFold, ShuffleSplit\n",
    "from sklearn.preprocessing   import MinMaxScaler, StandardScaler, OneHotEncoder\n",
    "from sklearn.impute          import SimpleImputer\n",
    "from impyute.imputation.cs   import mice\n",
    "\n",
    "from sklearn.pipeline        import Pipeline, make_pipeline\n",
    "from sklearn.compose         import ColumnTransformer\n",
    "from sklearn.preprocessing   import FunctionTransformer\n",
    "\n",
    "#from sklearn.metrics         import accuracy_score\n",
    "#from sklearn.metrics         import ConfusionMatrixDisplay, confusion_matrix, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "638e0b85-2725-4fe8-a25b-b4ef6a3bc975",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "org_titanic_train = pd.read_csv('./data/train.csv')\n",
    "org_titanic_test  = pd.read_csv('./data/test.csv')\n",
    "# lowercase for feature names\n",
    "org_titanic_train.columns = [i.lower() for i in org_titanic_train.columns]\n",
    "org_titanic_test.columns  = [i.lower() for i in org_titanic_test.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca52c895-4873-41e7-b55c-9f9d39a229ec",
   "metadata": {
    "tags": []
   },
   "source": [
    "# STEP3: Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42a5b4af-a38e-465e-817b-155012b4bbae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extent_impute(inp_df):\n",
    "    '''\n",
    "    Extract new features and impute missing values. Look 'feature_extension_funcs.py' for functions.\n",
    "    '''\n",
    "    # Create features\n",
    "    inp_df = prices(define_groups(title_name(inp_df)))\n",
    "    # Impute by custom functions\n",
    "    inp_df = age_groups(age_filled_tit((cabin_filled(embarked_filled(inp_df)))))\n",
    "    \n",
    "    return inp_df\n",
    "\n",
    "inp_df = extent_impute(org_titanic_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74a9ce1a-90e6-4e64-8970-cfdc7f5e515e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = inp_df.drop(columns=['survived']).copy()\n",
    "y = inp_df['survived'].copy()\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb197896-d64d-42ab-98aa-eb2db1b5853e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 20) (712,) (179, 20) (179,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passengerid</th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>title</th>\n",
       "      <th>surname</th>\n",
       "      <th>famsize</th>\n",
       "      <th>grpsize</th>\n",
       "      <th>price</th>\n",
       "      <th>emb_fill</th>\n",
       "      <th>cabin_f_cat</th>\n",
       "      <th>age_filled_tit</th>\n",
       "      <th>age_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>332</td>\n",
       "      <td>1</td>\n",
       "      <td>Partner, Mr. Austen</td>\n",
       "      <td>male</td>\n",
       "      <td>45.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113043</td>\n",
       "      <td>28.5</td>\n",
       "      <td>C124</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>Partner</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>45.5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     passengerid  pclass                 name   sex   age  sibsp  parch   \n",
       "331          332       1  Partner, Mr. Austen  male  45.5      0      0  \\\n",
       "\n",
       "     ticket  fare cabin embarked title  surname  famsize  grpsize  price   \n",
       "331  113043  28.5  C124        S   Mr.  Partner        1      1.0     28  \\\n",
       "\n",
       "    emb_fill cabin_f_cat  age_filled_tit  age_group  \n",
       "331        S           1            45.5          3  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Xtrain.shape, Ytrain.shape, Xtest.shape, Ytest.shape)\n",
    "Xtrain.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f80390-93e9-4c8d-a765-3ac517a4d5a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# STEP 4: Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df836119-6059-4651-ac7e-0be8babf7fde",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preprocessing: Pipelines & Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "091b5bd8-a202-4c9c-ab11-242ce88fe819",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dictionaries for data and models\n",
    "train_test_dict = {\"train\": [[Xtrain, Ytrain],'train'], \"test\": [[Xtest, Ytest],'test']}\n",
    "\n",
    "model_dict = {\n",
    "    \"logr\": [LogisticRegression(),'Logistic Reg.'],\n",
    "    \"dtc\" : [DecisionTreeClassifier(), 'Decision Tree'] ,\n",
    "    \"rfc\" : [RandomForestClassifier(), 'Random Forest']\n",
    "}\n",
    "\n",
    "#The Features!\n",
    "features_dict= {'num_features' : ['age','famsize', 'price'],\n",
    "                'cat_features' : ['pclass','sex','title','emb_fill','age_group', 'grpsize', 'famsize',  'cabin', 'surname'],\n",
    "                'no_features'  : ['age_filled_tit', 'cabin_f_cat'],\n",
    "                'drop_features': ['passengerid', 'name', 'sibsp', 'parch', 'ticket', 'fare', 'embarked']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a64db86-de0b-4ddb-8a05-89253a6519ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_model(xy_dict, param_grid, model_abrv, text=True, plt_data=True):\n",
    "    '''\n",
    "    Get scores for the given model.\n",
    "    \n",
    "    xy_dict    : Combined data train+test\n",
    "    model_abrv : Abbreviation of models in the dict.\n",
    "    sco_df     : Output data\n",
    "    plt_data   : Plt confusion matrix and ROC\n",
    "    text       : Information as print \n",
    "    \n",
    "    '''\n",
    "    sco_df=pd.DataFrame()\n",
    "    score_temp_df = pd.DataFrame(columns=['Model_Name'])\n",
    "    model = model_dict[model_abrv][0]\n",
    "    \n",
    "    # Organize train and test data to procees seperately from the dictionary\n",
    "    for label, dfs in xy_dict.items():\n",
    "        model_name = model_dict[model_abrv][1] + f'_{label}'\n",
    "        x = dfs[0][0]\n",
    "        y = dfs[0][1]\n",
    "        \n",
    "        #Build Pipelines\n",
    "        built_pipeline = build_model_pipeline(model)\n",
    "        built_pipeline = built_pipeline.fit(x,y)\n",
    "        \n",
    "        #Optimize Hyperparameters\n",
    "        grid_pipeline = grid(built_pipeline, x, y, param_grid)\n",
    "        \n",
    "        #Scores: \n",
    "        score      = round(built_pipeline.score(x,y), 2)\n",
    "        grid_score = round(grid_pipeline.best_estimator_.score(x,y), 2)\n",
    "        y_pred     = grid_pipeline.best_estimator_.predict(x)\n",
    "        \n",
    "       \n",
    "        accuracy      = round(metrics.accuracy_score (y, y_pred),2)\n",
    "        precision     = round(metrics.precision_score(y, y_pred, pos_label=1),2)\n",
    "        recall        = round(metrics.precision_score(y, y_pred, pos_label=1),2)\n",
    "        f1            = round(metrics.f1_score       (y, y_pred),2)\n",
    "        cv_score      = ss_cross_val(x, y, built_pipeline)\n",
    "        \n",
    "        # Print scores\n",
    "        if text:\n",
    "            print(f'=========== Results of {model_name}:')\n",
    "            print(f'Score        {label}: {score:.4}')\n",
    "            print(f'Grid Score   {label}: {grid_score:.4}')\n",
    "            print(f'SS-Cross-Val {label}:')\n",
    "            print(f\"  CV-Score Val-Train: {cv_score['train_score'].mean():.4} \\u00B1 {cv_score['train_score'].std():.4}\")\n",
    "            print(f\"  CV-Score Val-Test : {cv_score['test_score'].mean():.4} \\u00B1 {cv_score['test_score'].std():.4}\")\n",
    "            print(f'Accuracy     {label}: {accuracy:.4}')\n",
    "            print(f'Precision    {label}: {precision:.4}')\n",
    "            print(f'Recall       {label}: {recall:.4}')\n",
    "            print(f'F1           {label}: {f1:.4}')\n",
    "\n",
    "        \n",
    "        #Plot confusion matrix and ROC\n",
    "        if plt_data:\n",
    "            plot_data(x, y, y_pred, built_pipeline, model_name)\n",
    "\n",
    "        #For kaggle test set, output the predictions ax csv files\n",
    "        if label == 'kaggle':\n",
    "            kaggle_predict(grid_pipeline, model_name)\n",
    "        \n",
    "        \n",
    "        #Save results from all models in same dataframe\n",
    "        score_temp_df = pd.DataFrame([[ model_name, score,    grid_score,accuracy  , precision  ,recall   ,f1   , cv_score['train_score'].mean(), cv_score['train_score'].std(), cv_score['test_score'].mean(), cv_score['test_score'].std()]],\n",
    "                             columns=['Model_Name','Score', 'Grid Score','Accuracy', 'Precision', 'Recall', 'F1', 'Cross-Val-train-mean',        'Cross-Val-train-std',          'Cross-Val-test-mean',         'Cross-Val-test-std'])\n",
    "        sco_df = pd.concat([sco_df, score_temp_df], axis=0)\n",
    "    \n",
    "    return sco_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22306a56-4dd6-4f6b-a806-b1175bebcd54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import set_config\n",
    "set_config(display=\"diagram\")\n",
    "\n",
    "def build_model_pipeline(model):\n",
    "    cat_pipe = make_pipeline(SimpleImputer(strategy='most_frequent'),\n",
    "                             OneHotEncoder(handle_unknown='ignore')\n",
    "                            )\n",
    "\n",
    "    num_pipe = make_pipeline(SimpleImputer(strategy='median'),\n",
    "                             MinMaxScaler()\n",
    "                            )\n",
    "    \n",
    "    transformer = ColumnTransformer(\n",
    "        transformers=[('num',  num_pipe, features_dict['num_features']),\n",
    "                      ('cat',  cat_pipe, features_dict['cat_features'])],\n",
    "                    remainder='drop')\n",
    "    \n",
    "    pipe = Pipeline([('feature_transformer', transformer), \n",
    "                     ('model', model)])\n",
    "    \n",
    "    pipe\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c0027db-d13a-4c6b-8b6e-d94b39de5175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid(built_pipeline, x, y , param_grid):\n",
    "    '''\n",
    "    Hyperparemeter optimization with given values\n",
    "    '''\n",
    "    \n",
    "    gridsearch = GridSearchCV(built_pipeline, \n",
    "                          param_grid, \n",
    "                          cv=cv_ss,\n",
    "                          scoring='accuracy',\n",
    "                          n_jobs  = -1, \n",
    "                          verbose = 0)      \n",
    "        \n",
    "    gridsearch.fit(x,y)\n",
    "    gridsearch.scorer_\n",
    "    #print(gridsearch.get_params().keys())\n",
    "    #print(gridsearch.best_score_)\n",
    "    #pd.DataFrame(gridsearch.cv_results_).sort_values('rank_test_score')\n",
    "    \n",
    "    print(f'\\nBest hyperparameters: {gridsearch.best_params_}')\n",
    "    return gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ea52c05-ccdd-4c91-8a2d-989e4e52e5f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv_ss = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "\n",
    "def ss_cross_val(x, y, built_model):\n",
    "    '''\n",
    "    Get Cross Validation score by shufflesplit.\n",
    "    Output train and test validate scores as STR\n",
    "    '''\n",
    "\n",
    "    scores_ss = cross_validate(\n",
    "    estimator = built_model, # model to evaluate\n",
    "    X = x,\n",
    "    y = y,\n",
    "    cv = cv_ss,    # no. of cross-validation split\n",
    "    scoring ='r2', # evaluation metric\n",
    "    return_train_score=True\n",
    "    )\n",
    "    \n",
    "    return scores_ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "035ba859-5df8-4bfe-956d-beb721110519",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_data(x, y, y_pred, built_pipeline, model_name):\n",
    "        '''\n",
    "        Plot confusion matrix and RoC Curve\n",
    "    \n",
    "        '''  \n",
    "        metrics.ConfusionMatrixDisplay.from_predictions(y, y_pred, normalize=None)\n",
    "        plt.title(f\"{model_name} - Confusion Matrix\")\n",
    "        roc_auc = metrics.RocCurveDisplay.from_estimator(built_pipeline, X=x, y=y)\n",
    "        plt.title(f\"{model_name} - ROC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6cb40ec1-5a00-4937-a157-7609bafc17d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#This functions train models on whole Kaggle_train data and estimates with best parameters Kaggle_test data and save as csv\n",
    "def kaggle_predict(grid_pipeline, model_name):\n",
    "    y_pred_kaggle_test = grid_pipeline.best_estimator_.predict(X_kag_test)\n",
    "    kag_df = pd.concat([passenger_list, pd.Series(y_pred_kaggle_test, name='Survived')], axis=1, join='outer')\n",
    "    kag_df.to_csv(f'\\kaggle_pred\\ {model_name}.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0734b67e-3bb4-48ea-b60e-0736d5da44c1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# STEP5: Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f87704ab-e209-4d2a-b83e-4439adf3d415",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_scores_df  = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80c35e9-7eb5-4abb-885c-10e305df161a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Feature Set 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c8add68-9333-43c1-ae61-88118c725037",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Model with original features\n",
    "features_dict1 = {'num_features' : ['age', 'fare', 'sibsp', 'parch'],\n",
    "                'cat_features' : ['pclass','sex', 'embarked', 'cabin'],\n",
    "                'drop_features': ['passengerid', 'name', 'ticket']}\n",
    "features_dict  = features_dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a947f6f8-635c-4497-a86f-f10662cff12e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best hyperparameters: {'model__max_iter': 100, 'model__random_state': 30}\n",
      "=========== Results of Logistic Reg._train:\n",
      "Score        train: 0.84\n",
      "Grid Score   train: 0.84\n",
      "SS-Cross-Val train:\n",
      "  CV-Score Val-Train: 0.333 ± 0.02523\n",
      "  CV-Score Val-Test : 0.09443 ± 0.1075\n",
      "Accuracy     train: 0.84\n",
      "Precision    train: 0.81\n",
      "Recall       train: 0.81\n",
      "F1           train: 0.78\n",
      "\n",
      "Best hyperparameters: {'model__max_iter': 100, 'model__random_state': 30}\n",
      "=========== Results of Logistic Reg._test:\n",
      "Score        test: 0.84\n",
      "Grid Score   test: 0.84\n",
      "SS-Cross-Val test:\n",
      "  CV-Score Val-Train: 0.3535 ± 0.07206\n",
      "  CV-Score Val-Test : 0.08517 ± 0.286\n",
      "Accuracy     test: 0.84\n",
      "Precision    test: 0.8\n",
      "Recall       test: 0.8\n",
      "F1           test: 0.81\n",
      "\n",
      "Best hyperparameters: {'model__max_depth': 7, 'model__random_state': 42}\n",
      "=========== Results of Decision Tree_train:\n",
      "Score        train: 0.98\n",
      "Grid Score   train: 0.89\n",
      "SS-Cross-Val train:\n",
      "  CV-Score Val-Train: 0.9478 ± 0.008215\n",
      "  CV-Score Val-Test : 0.03598 ± 0.07113\n",
      "Accuracy     train: 0.89\n",
      "Precision    train: 0.95\n",
      "Recall       train: 0.95\n",
      "F1           train: 0.84\n",
      "\n",
      "Best hyperparameters: {'model__max_depth': 6, 'model__random_state': 22}\n",
      "=========== Results of Decision Tree_test:\n",
      "Score        test: 1.0\n",
      "Grid Score   test: 0.89\n",
      "SS-Cross-Val test:\n",
      "  CV-Score Val-Train: 1.0 ± 0.0\n",
      "  CV-Score Val-Test : -0.2543 ± 0.2751\n",
      "Accuracy     test: 0.89\n",
      "Precision    test: 0.81\n",
      "Recall       test: 0.81\n",
      "F1           test: 0.88\n",
      "\n",
      "Best hyperparameters: {'model__max_depth': 200, 'model__n_estimators': 150}\n",
      "=========== Results of Random Forest_train:\n",
      "Score        train: 0.98\n",
      "Grid Score   train: 0.98\n",
      "SS-Cross-Val train:\n",
      "  CV-Score Val-Train: 0.9478 ± 0.008215\n",
      "  CV-Score Val-Test : 0.04536 ± 0.1544\n",
      "Accuracy     train: 0.98\n",
      "Precision    train: 1.0\n",
      "Recall       train: 1.0\n",
      "F1           train: 0.98\n",
      "\n",
      "Best hyperparameters: {'model__max_depth': 200, 'model__n_estimators': 150}\n",
      "=========== Results of Random Forest_test:\n",
      "Score        test: 1.0\n",
      "Grid Score   test: 1.0\n",
      "SS-Cross-Val test:\n",
      "  CV-Score Val-Train: 1.0 ± 0.0\n",
      "  CV-Score Val-Test : -0.08455 ± 0.2418\n",
      "Accuracy     test: 1.0\n",
      "Precision    test: 1.0\n",
      "Recall       test: 1.0\n",
      "F1           test: 1.0\n"
     ]
    }
   ],
   "source": [
    "param_grid    = {'model__max_iter'     : [100, 150, 200],\n",
    "                 'model__random_state' : [30, 42, 100]\n",
    "}\n",
    "all_scores_df = pd.concat([all_scores_df, run_model(train_test_dict, param_grid, 'logr', plt_data=False)], axis=0)\n",
    "\n",
    "param_grid    = {'model__max_depth': [5, 6, 7],\n",
    "                'model__random_state' : [22, 42, 100]\n",
    "                }\n",
    "all_scores_df = pd.concat([all_scores_df, run_model(train_test_dict, param_grid, 'dtc', plt_data=False)], axis=0)\n",
    "\n",
    "param_grid    = {'model__max_depth': [200], 'model__n_estimators': [150 , 200, 250]}\n",
    "all_scores_df = pd.concat([all_scores_df, run_model(train_test_dict, param_grid, 'rfc', plt_data=False)], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a25ecc-4e3a-4e1b-95a3-0e8849f451da",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Feature Set 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "343c43c2-62dd-4a18-9665-59475c604ee4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_dict2 = {'num_features' : ['age','famsize', 'price'],\n",
    "                'cat_features' : ['pclass','sex','title','emb_fill','age_group', 'grpsize', 'famsize',  'cabin', 'surname'],}\n",
    "\n",
    "features_dict  = features_dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4dba761-2a2a-407c-a692-63b95f8f9a7d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best hyperparameters: {'model__max_iter': 100, 'model__random_state': 15}\n",
      "=========== Results of Logistic Reg._train:\n",
      "Score        train: 0.9\n",
      "Grid Score   train: 0.9\n",
      "SS-Cross-Val train:\n",
      "  CV-Score Val-Train: 0.5912 ± 0.02276\n",
      "  CV-Score Val-Test : 0.2542 ± 0.06782\n",
      "Accuracy     train: 0.9\n",
      "Precision    train: 0.9\n",
      "Recall       train: 0.9\n",
      "F1           train: 0.86\n",
      "\n",
      "Best hyperparameters: {'model__max_iter': 100, 'model__random_state': 15}\n",
      "=========== Results of Logistic Reg._test:\n",
      "Score        test: 0.92\n",
      "Grid Score   test: 0.92\n",
      "SS-Cross-Val test:\n",
      "  CV-Score Val-Train: 0.7027 ± 0.03731\n",
      "  CV-Score Val-Test : -0.02143 ± 0.1854\n",
      "Accuracy     test: 0.92\n",
      "Precision    test: 0.9\n",
      "Recall       test: 0.9\n",
      "F1           test: 0.9\n",
      "\n",
      "Best hyperparameters: {'model__max_depth': 20, 'model__random_state': 100}\n",
      "=========== Results of Decision Tree_train:\n",
      "Score        train: 1.0\n",
      "Grid Score   train: 0.97\n",
      "SS-Cross-Val train:\n",
      "  CV-Score Val-Train: 0.997 ± 0.003666\n",
      "  CV-Score Val-Test : 0.1749 ± 0.1463\n",
      "Accuracy     train: 0.97\n",
      "Precision    train: 1.0\n",
      "Recall       train: 1.0\n",
      "F1           train: 0.96\n",
      "\n",
      "Best hyperparameters: {'model__max_depth': 5, 'model__random_state': 42}\n",
      "=========== Results of Decision Tree_test:\n",
      "Score        test: 1.0\n",
      "Grid Score   test: 0.96\n",
      "SS-Cross-Val test:\n",
      "  CV-Score Val-Train: 1.0 ± 0.0\n",
      "  CV-Score Val-Test : 0.2716 ± 0.08976\n",
      "Accuracy     test: 0.96\n",
      "Precision    test: 0.95\n",
      "Recall       test: 0.95\n",
      "F1           test: 0.95\n",
      "\n",
      "Best hyperparameters: {'model__max_depth': 200, 'model__n_estimators': 200}\n",
      "=========== Results of Random Forest_train:\n",
      "Score        train: 1.0\n",
      "Grid Score   train: 1.0\n",
      "SS-Cross-Val train:\n",
      "  CV-Score Val-Train: 0.997 ± 0.003666\n",
      "  CV-Score Val-Test : 0.1498 ± 0.08456\n",
      "Accuracy     train: 1.0\n",
      "Precision    train: 1.0\n",
      "Recall       train: 1.0\n",
      "F1           train: 1.0\n",
      "\n",
      "Best hyperparameters: {'model__max_depth': 200, 'model__n_estimators': 150}\n",
      "=========== Results of Random Forest_test:\n",
      "Score        test: 1.0\n",
      "Grid Score   test: 1.0\n",
      "SS-Cross-Val test:\n",
      "  CV-Score Val-Train: 1.0 ± 0.0\n",
      "  CV-Score Val-Test : -0.01537 ± 0.2151\n",
      "Accuracy     test: 1.0\n",
      "Precision    test: 1.0\n",
      "Recall       test: 1.0\n",
      "F1           test: 1.0\n"
     ]
    }
   ],
   "source": [
    "param_grid    = {'model__max_iter'     : [100, 150, 200],\n",
    "                 'model__random_state' : [15, 30, 42]\n",
    "}\n",
    "all_scores_df = pd.concat([all_scores_df, run_model(train_test_dict, param_grid, 'logr', plt_data=False)], axis=0)\n",
    "\n",
    "param_grid    = {'model__max_depth': [2, 5, 6, 20],\n",
    "                'model__random_state' : [22, 42, 100]\n",
    "                }\n",
    "all_scores_df = pd.concat([all_scores_df, run_model(train_test_dict, param_grid, 'dtc', plt_data=False)], axis=0)\n",
    "\n",
    "param_grid    = {'model__max_depth': [200], 'model__n_estimators': [150 , 200, 250]}\n",
    "all_scores_df = pd.concat([all_scores_df, run_model(train_test_dict, param_grid, 'rfc', plt_data=False)], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cace33c-3e32-4626-bedc-a644589a5b5e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Feature Set 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2c9e533-0bfb-4586-9ba6-b27dbcf44446",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_dict3 = {'num_features' : ['age_filled_tit', 'price'],\n",
    "                'cat_features' : ['grpsize', 'pclass','sex','title','emb_fill', 'cabin']}\n",
    "\n",
    "features_dict  = features_dict3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0933cf2-8537-4fbc-bb56-f27939ade06f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best hyperparameters: {'model__max_iter': 100, 'model__random_state': 15}\n",
      "=========== Results of Logistic Reg._train:\n",
      "Score        train: 0.87\n",
      "Grid Score   train: 0.87\n",
      "SS-Cross-Val train:\n",
      "  CV-Score Val-Train: 0.4196 ± 0.01986\n",
      "  CV-Score Val-Test : 0.2657 ± 0.08528\n",
      "Accuracy     train: 0.87\n",
      "Precision    train: 0.83\n",
      "Recall       train: 0.83\n",
      "F1           train: 0.82\n",
      "\n",
      "Best hyperparameters: {'model__max_iter': 100, 'model__random_state': 15}\n",
      "=========== Results of Logistic Reg._test:\n",
      "Score        test: 0.88\n",
      "Grid Score   test: 0.88\n",
      "SS-Cross-Val test:\n",
      "  CV-Score Val-Train: 0.5139 ± 0.05865\n",
      "  CV-Score Val-Test : 0.04889 ± 0.2086\n",
      "Accuracy     test: 0.88\n",
      "Precision    test: 0.86\n",
      "Recall       test: 0.86\n",
      "F1           test: 0.86\n",
      "\n",
      "Best hyperparameters: {'model__max_depth': 2, 'model__random_state': 42}\n",
      "=========== Results of Decision Tree_train:\n",
      "Score        train: 0.97\n",
      "Grid Score   train: 0.8\n",
      "SS-Cross-Val train:\n",
      "  CV-Score Val-Train: 0.8791 ± 0.007802\n",
      "  CV-Score Val-Test : 0.02747 ± 0.2259\n",
      "Accuracy     train: 0.8\n",
      "Precision    train: 0.94\n",
      "Recall       train: 0.94\n",
      "F1           train: 0.66\n",
      "\n",
      "Best hyperparameters: {'model__max_depth': 5, 'model__random_state': 42}\n",
      "=========== Results of Decision Tree_test:\n",
      "Score        test: 1.0\n",
      "Grid Score   test: 0.94\n",
      "SS-Cross-Val test:\n",
      "  CV-Score Val-Train: 1.0 ± 0.0\n",
      "  CV-Score Val-Test : 0.2054 ± 0.1937\n",
      "Accuracy     test: 0.94\n",
      "Precision    test: 0.9\n",
      "Recall       test: 0.9\n",
      "F1           test: 0.93\n",
      "\n",
      "Best hyperparameters: {'model__max_depth': 200, 'model__n_estimators': 200}\n",
      "=========== Results of Random Forest_train:\n",
      "Score        train: 0.97\n",
      "Grid Score   train: 0.97\n",
      "SS-Cross-Val train:\n",
      "  CV-Score Val-Train: 0.8791 ± 0.007802\n",
      "  CV-Score Val-Test : 0.1059 ± 0.1222\n",
      "Accuracy     train: 0.97\n",
      "Precision    train: 0.98\n",
      "Recall       train: 0.98\n",
      "F1           train: 0.96\n",
      "\n",
      "Best hyperparameters: {'model__max_depth': 200, 'model__n_estimators': 150}\n",
      "=========== Results of Random Forest_test:\n",
      "Score        test: 1.0\n",
      "Grid Score   test: 1.0\n",
      "SS-Cross-Val test:\n",
      "  CV-Score Val-Train: 1.0 ± 0.0\n",
      "  CV-Score Val-Test : 0.02144 ± 0.195\n",
      "Accuracy     test: 1.0\n",
      "Precision    test: 1.0\n",
      "Recall       test: 1.0\n",
      "F1           test: 1.0\n"
     ]
    }
   ],
   "source": [
    "param_grid    = {'model__max_iter'     : [100, 150],\n",
    "                 'model__random_state' : [15, 30, 42]\n",
    "}\n",
    "all_scores_df = pd.concat([all_scores_df, run_model(train_test_dict, param_grid, 'logr', plt_data=False)], axis=0)\n",
    "\n",
    "param_grid    = {'model__max_depth': [2, 5, 8],\n",
    "                'model__random_state' : [42, 100, 142]\n",
    "                }\n",
    "all_scores_df = pd.concat([all_scores_df, run_model(train_test_dict, param_grid, 'dtc', plt_data=False)], axis=0)\n",
    "\n",
    "param_grid    = {'model__max_depth': [200], 'model__n_estimators': [150 , 200, 250]}\n",
    "all_scores_df = pd.concat([all_scores_df, run_model(train_test_dict, param_grid, 'rfc', plt_data=False)], axis=0)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7906b02e-991c-485b-bd2a-8bd4d788fceb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# FULL LIST\n",
    "features_dict= {'num_features' : ['age','famsize', 'price'],\n",
    "                'cat_features' : ['pclass','sex','title','emb_fill','age_group', 'grpsize', 'famsize',  'cabin', 'surname'],\n",
    "                'no_features'  : ['age_filled_tit', 'cabin_f_cat'],\n",
    "                'drop_features': ['passengerid', 'name', 'sibsp', 'parch', 'ticket', 'fare', 'embarked']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6b8f82-209d-421a-8ce6-9a7098b87a82",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Models Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60d3a18a-3b0a-4a92-8631-1eabac52e04e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_Name</th>\n",
       "      <th>Score</th>\n",
       "      <th>Grid Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Cross-Val-train-mean</th>\n",
       "      <th>Cross-Val-train-std</th>\n",
       "      <th>Cross-Val-test-mean</th>\n",
       "      <th>Cross-Val-test-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Reg._train</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.332959</td>\n",
       "      <td>0.025225</td>\n",
       "      <td>0.094430</td>\n",
       "      <td>0.107457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Reg._test</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.353459</td>\n",
       "      <td>0.072055</td>\n",
       "      <td>0.085174</td>\n",
       "      <td>0.285965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree_train</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.947762</td>\n",
       "      <td>0.008215</td>\n",
       "      <td>0.035983</td>\n",
       "      <td>0.071133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree_test</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.254281</td>\n",
       "      <td>0.275061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest_train</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.947762</td>\n",
       "      <td>0.008215</td>\n",
       "      <td>0.045365</td>\n",
       "      <td>0.154422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest_test</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.084554</td>\n",
       "      <td>0.241764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Reg._train</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.591156</td>\n",
       "      <td>0.022763</td>\n",
       "      <td>0.254222</td>\n",
       "      <td>0.067823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Reg._test</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.702709</td>\n",
       "      <td>0.037310</td>\n",
       "      <td>-0.021426</td>\n",
       "      <td>0.185436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree_train</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.997007</td>\n",
       "      <td>0.003666</td>\n",
       "      <td>0.174867</td>\n",
       "      <td>0.146313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree_test</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.271612</td>\n",
       "      <td>0.089762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest_train</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.997007</td>\n",
       "      <td>0.003666</td>\n",
       "      <td>0.149753</td>\n",
       "      <td>0.084563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest_test</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.015367</td>\n",
       "      <td>0.215135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Reg._train</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.419569</td>\n",
       "      <td>0.019859</td>\n",
       "      <td>0.265747</td>\n",
       "      <td>0.085285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Reg._test</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.513924</td>\n",
       "      <td>0.058651</td>\n",
       "      <td>0.048889</td>\n",
       "      <td>0.208646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree_train</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.879105</td>\n",
       "      <td>0.007802</td>\n",
       "      <td>0.027469</td>\n",
       "      <td>0.225926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree_test</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.205429</td>\n",
       "      <td>0.193720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest_train</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.879105</td>\n",
       "      <td>0.007802</td>\n",
       "      <td>0.105907</td>\n",
       "      <td>0.122197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest_test</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021438</td>\n",
       "      <td>0.195023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model_Name  Score  Grid Score  Accuracy  Precision  Recall    F1   \n",
       "0  Logistic Reg._train   0.84        0.84      0.84       0.81    0.81  0.78  \\\n",
       "0   Logistic Reg._test   0.84        0.84      0.84       0.80    0.80  0.81   \n",
       "0  Decision Tree_train   0.98        0.89      0.89       0.95    0.95  0.84   \n",
       "0   Decision Tree_test   1.00        0.89      0.89       0.81    0.81  0.88   \n",
       "0  Random Forest_train   0.98        0.98      0.98       1.00    1.00  0.98   \n",
       "0   Random Forest_test   1.00        1.00      1.00       1.00    1.00  1.00   \n",
       "0  Logistic Reg._train   0.90        0.90      0.90       0.90    0.90  0.86   \n",
       "0   Logistic Reg._test   0.92        0.92      0.92       0.90    0.90  0.90   \n",
       "0  Decision Tree_train   1.00        0.97      0.97       1.00    1.00  0.96   \n",
       "0   Decision Tree_test   1.00        0.96      0.96       0.95    0.95  0.95   \n",
       "0  Random Forest_train   1.00        1.00      1.00       1.00    1.00  1.00   \n",
       "0   Random Forest_test   1.00        1.00      1.00       1.00    1.00  1.00   \n",
       "0  Logistic Reg._train   0.87        0.87      0.87       0.83    0.83  0.82   \n",
       "0   Logistic Reg._test   0.88        0.88      0.88       0.86    0.86  0.86   \n",
       "0  Decision Tree_train   0.97        0.80      0.80       0.94    0.94  0.66   \n",
       "0   Decision Tree_test   1.00        0.94      0.94       0.90    0.90  0.93   \n",
       "0  Random Forest_train   0.97        0.97      0.97       0.98    0.98  0.96   \n",
       "0   Random Forest_test   1.00        1.00      1.00       1.00    1.00  1.00   \n",
       "\n",
       "   Cross-Val-train-mean  Cross-Val-train-std  Cross-Val-test-mean   \n",
       "0              0.332959             0.025225             0.094430  \\\n",
       "0              0.353459             0.072055             0.085174   \n",
       "0              0.947762             0.008215             0.035983   \n",
       "0              1.000000             0.000000            -0.254281   \n",
       "0              0.947762             0.008215             0.045365   \n",
       "0              1.000000             0.000000            -0.084554   \n",
       "0              0.591156             0.022763             0.254222   \n",
       "0              0.702709             0.037310            -0.021426   \n",
       "0              0.997007             0.003666             0.174867   \n",
       "0              1.000000             0.000000             0.271612   \n",
       "0              0.997007             0.003666             0.149753   \n",
       "0              1.000000             0.000000            -0.015367   \n",
       "0              0.419569             0.019859             0.265747   \n",
       "0              0.513924             0.058651             0.048889   \n",
       "0              0.879105             0.007802             0.027469   \n",
       "0              1.000000             0.000000             0.205429   \n",
       "0              0.879105             0.007802             0.105907   \n",
       "0              1.000000             0.000000             0.021438   \n",
       "\n",
       "   Cross-Val-test-std  \n",
       "0            0.107457  \n",
       "0            0.285965  \n",
       "0            0.071133  \n",
       "0            0.275061  \n",
       "0            0.154422  \n",
       "0            0.241764  \n",
       "0            0.067823  \n",
       "0            0.185436  \n",
       "0            0.146313  \n",
       "0            0.089762  \n",
       "0            0.084563  \n",
       "0            0.215135  \n",
       "0            0.085285  \n",
       "0            0.208646  \n",
       "0            0.225926  \n",
       "0            0.193720  \n",
       "0            0.122197  \n",
       "0            0.195023  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c1adef-d2ac-49c1-bde1-e892dc8a13b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "Hyperparemeters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877b9928-56ea-495c-a6ed-514f7c6f77a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# STEP6: Calculate Test Score (Submit Predictions to Kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5e2ceaa-8c7d-45e6-9a65-5d51486972b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_kaggle_score = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3141c5c1-dd07-4d78-98bd-0265e934d847",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create & Impute features\n",
    "inp_df2      = extent_impute(org_titanic_train)\n",
    "kag_test_df  = org_titanic_test.copy()\n",
    "kag_test_df.fillna(value=7, inplace=True) #Missing value from pclass3, median is 7 for pclass3\n",
    "kag_test_df  = extent_impute(kag_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3e6b20cd-d991-4b28-963f-4c343ae43573",
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger_list      = kag_test_df['passengerid']\n",
    "passenger_list.name = 'PassengerId'\n",
    "\n",
    "X_kag_test          = kag_test_df\n",
    "\n",
    "X_kag               = inp_df2.drop(columns=['survived'])\n",
    "Y_kag               = inp_df2['survived']\n",
    "kaggle_train_dict   = {\"kaggle\": [[X_kag, Y_kag],'kaggle']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f780da25-742c-4b23-87cd-88adedadc987",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best hyperparameters: {'model__max_iter': 100, 'model__random_state': 15}\n",
      "=========== Results of Logistic Reg._kaggle:\n",
      "Score        kaggle: 0.83\n",
      "Grid Score   kaggle: 0.83\n",
      "SS-Cross-Val kaggle:\n",
      "  CV-Score Val-Train: 0.2988 ± 0.01734\n",
      "  CV-Score Val-Test : 0.2055 ± 0.06172\n",
      "Accuracy     kaggle: 0.83\n",
      "Precision    kaggle: 0.8\n",
      "Recall       kaggle: 0.8\n",
      "F1           kaggle: 0.78\n"
     ]
    }
   ],
   "source": [
    "features_dict  = features_dict1\n",
    "param_grid    = {'model__max_iter'     : [100, 150],\n",
    "                 'model__random_state' : [15, 30, 42]\n",
    "}\n",
    "all_kaggle_score = pd.concat([all_scores_df, run_model(kaggle_train_dict, param_grid, 'logr', plt_data=False)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d3480015-ea71-4ca4-9834-79eed7470ad1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best hyperparameters: {'model__max_iter': 100, 'model__random_state': 15}\n",
      "=========== Results of Logistic Reg._kaggle:\n",
      "Score        kaggle: 0.9\n",
      "Grid Score   kaggle: 0.9\n",
      "SS-Cross-Val kaggle:\n",
      "  CV-Score Val-Train: 0.5687 ± 0.01902\n",
      "  CV-Score Val-Test : 0.3804 ± 0.0865\n",
      "Accuracy     kaggle: 0.9\n",
      "Precision    kaggle: 0.89\n",
      "Recall       kaggle: 0.89\n",
      "F1           kaggle: 0.87\n"
     ]
    }
   ],
   "source": [
    "features_dict  = features_dict2\n",
    "param_grid    = {'model__max_iter'     : [100, 150],\n",
    "                 'model__random_state' : [15, 30, 42]\n",
    "}\n",
    "all_kaggle_score = pd.concat([all_scores_df, run_model(kaggle_train_dict, param_grid, 'logr', plt_data=False)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "36f14dcc-7aa6-457b-b5d5-eb5c23c6f2ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best hyperparameters: {'model__max_iter': 100, 'model__random_state': 15}\n",
      "=========== Results of Logistic Reg._kaggle:\n",
      "Score        kaggle: 0.87\n",
      "Grid Score   kaggle: 0.87\n",
      "SS-Cross-Val kaggle:\n",
      "  CV-Score Val-Train: 0.4234 ± 0.01366\n",
      "  CV-Score Val-Test : 0.3383 ± 0.1116\n",
      "Accuracy     kaggle: 0.87\n",
      "Precision    kaggle: 0.84\n",
      "Recall       kaggle: 0.84\n",
      "F1           kaggle: 0.82\n"
     ]
    }
   ],
   "source": [
    "features_dict  = features_dict3\n",
    "param_grid    = {'model__max_iter'     : [100, 150],\n",
    "                 'model__random_state' : [15, 30, 42]\n",
    "}\n",
    "all_kaggle_score = pd.concat([all_scores_df, run_model(kaggle_train_dict, param_grid, 'logr', plt_data=False)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a124cd2d-a94b-4636-801c-40b82e41bb30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
